# ğŸ•µï¸ DÃ©tection et Classification de Fake News avec LLM (RoBERTa) â€” V3 OptimisÃ©e

[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.x-ee4c2c.svg)](https://pytorch.org/)
[![Transformers](https://img.shields.io/badge/ğŸ¤—_Transformers-4.x-yellow.svg)](https://huggingface.co/transformers/)
[![Gradio](https://img.shields.io/badge/Gradio-UI-orange.svg)](https://gradio.app/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

> **Projet Master SDIA** â€” NLP & Web Mining  
> Un pipeline **robuste** et **honnÃªte** de Deep Learning pour dÃ©tecter les fake news, utilisant **RoBERTa** avec stratÃ©gies avancÃ©es de rÃ©gularisation, dÃ©duplication stricte et seuil dynamique.

---

## ğŸ“– Table des MatiÃ¨res

- [AperÃ§u du Projet](#-aperÃ§u-du-projet)
- [DÃ©monstration](#-dÃ©monstration)
- [Architecture du ModÃ¨le](#-architecture-du-modÃ¨le)
- [Structure du Projet](#-structure-du-projet)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Pipeline d'EntraÃ®nement](#-pipeline-dentraÃ®nement)
- [Performances](#-performances)
- [Configuration](#-configuration)
- [RÃ©fÃ©rences](#-rÃ©fÃ©rences)

---

## ğŸ¯ AperÃ§u du Projet (V3 â€” OptimisÃ©e)

Cette version corrige les biais majeurs prÃ©sents dans la plupart des projets de dÃ©tection de fake news grÃ¢ce Ã  trois innovations techniques :

1. **ğŸ›¡ï¸ DÃ©duplication Stricte** : Suppression rigoureuse des doublons AVANT le split Train/Val (Ã©vite la fuite de donnÃ©es/data leakage)
2. **ğŸ§  Seuil de DÃ©cision Dynamique** : Au lieu d'utiliser un seuil fixe (0.50), le modÃ¨le trouve le seuil optimal (ex: 0.45 ou 0.60) qui maximise le F1-Score par dataset
3. **ğŸ“‰ RÃ©gularisation AvancÃ©e** : Dropout renforcÃ© (0.2) + **Focal Loss** pour empÃªcher l'overfitting sur les datasets bruyants

Le modÃ¨le utilise **RoBERTa** de Facebook/Meta, fine-tunÃ© sur les datasets **FakeNewsNet** (GossipCop & Politifact) avec validation stricte.

### FonctionnalitÃ©s Principales

| Composant           | V3 â€” Description                                                           |
| ------------------- | -------------------------------------------------------------------------- |
| ğŸ—ƒï¸ **DonnÃ©es**      | **DÃ©duplication stricte** des doublons (1397 supprimÃ©s dans GossipCop)     |
| ğŸ§  **ModÃ¨le**       | Fine-tuning de `roberta-base` (125M) avec **Dropout=0.2** anti-overfitting |
| ğŸ”¥ **Loss**         | **Focal Loss** ($\gamma=2$) + `WeightedRandomSampler` pour Ã©quilibrage     |
| ğŸ¯ **DÃ©cision**     | **Seuil Dynamique** : ~0.45 (PolitiFact), ~0.60 (GossipCop)                |
| ğŸš€ **Optimisation** | AdamW + Linear Warmup + Mixed Precision (FP16) + Early Stopping agressif   |
| ğŸ–¥ï¸ **Interface**    | Application web **Gradio** avec thÃ¨me personnalisÃ©                         |
| ğŸ“š **PÃ©dagogie**    | DÃ©mos interactives : tokenisation, analyse d'erreurs, visualisations       |

---

## ğŸ¬ DÃ©monstration

L'application analyse un texte et retourne :

- **âœ… Vrai (Real)** : Contenu vÃ©ridique et factuel
- **ğŸš¨ Faux (Fake)** : Contenu potentiellement trompeur ou fabriquÃ©

```
ğŸ“° Titre : "Pope Francis endorses Donald Trump for president."
   RÃ©sultat : ğŸš¨ FAUX (FAKE)
   Confiance: [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘] 82.3%
```

---

## ğŸ—ï¸ Architecture du ModÃ¨le

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        INPUT TEXT                           â”‚
â”‚         "Scientists confirm the earth is flat."             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RoBERTa TOKENIZER                        â”‚
â”‚  Tokens: ['Scientists', 'Ä confirm', 'Ä the', 'Ä earth', ...]  â”‚
â”‚  IDs:    [10868, 5765, 5, 4015, 16, 5765, 4, ...]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 RoBERTa ENCODER (12 layers)                 â”‚
â”‚            Attention Heads: 12 | Hidden: 768                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              CLASSIFICATION HEAD (Linear Layer)             â”‚
â”‚                    768 â†’ 2 (Real/Fake)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SOFTMAX OUTPUT                         â”‚
â”‚              [P(Real)=0.12, P(Fake)=0.88]                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Structure du Projet

```
fake-news-detection-and-classification/
â”‚
â”œâ”€â”€ ğŸ““ fake-news-detection-and-classification-using-llm.ipynb
â”‚       â””â”€â”€ Notebook principal d'entraÃ®nement (9 sections dÃ©taillÃ©es)
â”‚
â”œâ”€â”€ ğŸš€ app.py
â”‚       â””â”€â”€ Application Gradio pour l'infÃ©rence en temps rÃ©el
â”‚
â”œâ”€â”€ ğŸ“‹ requirements.txt
â”‚       â””â”€â”€ DÃ©pendances Python du projet
â”‚
â”œâ”€â”€ ğŸ“– README.md
â”‚       â””â”€â”€ Documentation principale (ce fichier)
â”‚
â””â”€â”€ ğŸ¤– mon_modele_fake_news/
        â”œâ”€â”€ config.json              # Configuration architecture RoBERTa
        â”œâ”€â”€ model.safetensors        # Poids du modÃ¨le (format sÃ©curisÃ©)
        â”œâ”€â”€ vocab.json               # Vocabulaire (50265 tokens)
        â”œâ”€â”€ merges.txt               # RÃ¨gles de fusion BPE
        â”œâ”€â”€ tokenizer_config.json    # Configuration du tokenizer
        â””â”€â”€ special_tokens_map.json  # Tokens spÃ©ciaux (<s>, </s>, <pad>)
```

---

## âš™ï¸ Installation

### PrÃ©requis

- **Python:** 3.8 ou supÃ©rieur
- **GPU:** RecommandÃ© pour l'entraÃ®nement (NVIDIA CUDA), optionnel pour l'infÃ©rence
- **RAM:** 8 Go minimum (16 Go recommandÃ©)

### Ã‰tapes d'Installation

```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/scorpionTaj/fake-news-detection-and-classification.git

# 2. AccÃ©der au rÃ©pertoire
cd fake-news-detection-and-classification

# 3. (Optionnel) CrÃ©er un environnement virtuel
python -m venv venv
# source venv/bin/activate     # Pour Bash/Zsh

# 4. Installer les dÃ©pendances
pip install -r requirements.txt
```

### DÃ©pendances Principales

| Package                  | Version | UtilitÃ©                         |
| ------------------------ | ------- | ------------------------------- |
| `torch`                  | â‰¥2.0    | Framework Deep Learning         |
| `transformers`           | â‰¥4.30   | ModÃ¨les prÃ©-entraÃ®nÃ©s (RoBERTa) |
| `gradio`                 | â‰¥4.0    | Interface web interactive       |
| `scikit-learn`           | â‰¥1.0    | MÃ©triques d'Ã©valuation          |
| `matplotlib` / `seaborn` | -       | Visualisations                  |

---

## ğŸš€ Utilisation

### 1. Lancer l'Application Web (InfÃ©rence)

Si vous avez dÃ©jÃ  le modÃ¨le entraÃ®nÃ© dans `mon_modele_fake_news/` :

```bash
python app.py
```

Ouvrez `http://127.0.0.1:7860` dans votre navigateur.

### 2. EntraÃ®ner le ModÃ¨le (Notebook)

Ouvrez le notebook dans Jupyter ou Google Colab :

```bash
jupyter notebook fake-news-detection-and-classification-using-llm.ipynb
```

---

## ğŸ”„ Pipeline d'EntraÃ®nement

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DONNÃ‰ES    â”‚ â†’ â”‚ PRÃ‰PARATION  â”‚ â†’ â”‚ ENTRAÃNEMENT â”‚ â†’ â”‚  Ã‰VALUATION  â”‚
â”‚  FakeNewsNet â”‚    â”‚  Nettoyage   â”‚    â”‚   RoBERTa    â”‚    â”‚   F1-Score   â”‚
â”‚  (CSV URLs)  â”‚    â”‚  Tokenisationâ”‚    â”‚   Fine-tune  â”‚    â”‚   Confusion  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
                    â”‚   DÃ‰MO WEB   â”‚ â† â”‚  SAUVEGARDE  â”‚ â†â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚    Gradio    â”‚    â”‚  .safetensorsâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Ã‰tapes DÃ©taillÃ©es

1. **Chargement** : TÃ©lÃ©chargement des 4 CSV (Politifact + GossipCop Ã— Real/Fake)
2. **EDA** : Analyse exploratoire (distribution, doublons, valeurs manquantes)
3. **PrÃ©traitement** : Nettoyage, tokenisation BPE, padding/truncation
4. **Ã‰quilibrage** : **Focal Loss (Î³=2)** + WeightedRandomSampler (double stratÃ©gie)
5. **Fine-tuning** : Jusqu'Ã  100 Ã©poques, Mixed Precision, Early Stopping (patience=4)
6. **Ã‰valuation** : F1-Score, Matrice de confusion, Rapport de classification
7. **Export** : Sauvegarde au format Hugging Face (.safetensors)

---

## ğŸ“Š Performances V3 (Sans Fuite de DonnÃ©es)

Contrairement aux approches classiques qui gonflent les scores via des doublons, ces rÃ©sultats sont **honnÃªtes** et validÃ©s sur des donnÃ©es uniques aprÃ¨s dÃ©duplication stricte.

### ğŸ›ï¸ PolitiFact (Politique)

> ModÃ¨le trÃ¨s performant, capable de saisir les nuances politiques.

| MÃ©trique          | RÃ©sultat |
| ----------------- | -------- |
| **F1-Score**      | ~0.89    |
| **Seuil Optimal** | **0.45** |
| **Erreurs**       | ~10/148  |

### ğŸŒŸ GossipCop (CÃ©lÃ©britÃ©s)

> Dataset difficile et bruyant (tabloÃ¯ds), stabilisÃ© par Dropout=0.2.

| MÃ©trique               | RÃ©sultat             |
| ---------------------- | -------------------- |
| **F1-Score**           | ~0.67                |
| **Seuil Optimal**      | **0.60**             |
| **Gain V3**            | Overfitting maÃ®trisÃ© |
| **Doublons supprimÃ©s** | 1397                 |

### Labels

- **Label 0** : âœ… Vrai (Real) â€” Article vÃ©rifiÃ© comme factuel
- **Label 1** : ğŸš¨ Faux (Fake) â€” Article identifiÃ© comme trompeur

> **Note** : Les scores V3 sont lÃ©gÃ¨rement infÃ©rieurs Ã  V2 (0.85 â†’ 0.67 sur GossipCop) car la dÃ©duplication a supprimÃ© les doublons qui gonflaient artificiellement les mÃ©triques. Ces scores V3 reflÃ¨tent la **vraie** capacitÃ© du modÃ¨le.

---

## ğŸ› ï¸ Configuration V3 (Robuste)

Les hyperparamÃ¨tres ont Ã©tÃ© ajustÃ©s pour la stabilitÃ© et l'honnÃªtetÃ© des Ã©valuations :

```python
class ProjectConfig:
    SEED = 42              # ReproductibilitÃ©
    MAX_LEN = 128          # Longueur max des sÃ©quences
    BATCH_SIZE = 32        # Petit batch pour meilleure gÃ©nÃ©ralisation
    EPOCHS = 8             # Early Stopping agressif pour capturer le pic
    LEARNING_RATE = 1e-5   # Taux trÃ¨s faible pour fine-tuning prÃ©cis
    WEIGHT_DECAY = 0.1     # RÃ©gularisation L2
    DROPOUT_RATE = 0.2     # AUGMENTÃ‰ (0.1 â†’ 0.2) pour anti-overfitting
    PATIENCE = 4           # Early stopping aprÃ¨s 4 Ã©poques
    MODEL_NAME = 'roberta-base'
```

### Focal Loss + Dropout RenforcÃ©

Le projet combine **Focal Loss** + **Dropout augmentÃ©** pour combattre le surapprentissage (overfitting), particuliÃ¨rement sur GossipCop (dataset bruyant).

| Technique           | ParamÃ¨tre        | RÃ´le                                                                          |
| ------------------- | ---------------- | ----------------------------------------------------------------------------- |
| **Focal Loss**      | gamma=2.0        | RÃ©duit le poids des exemples faciles, focus sur les fakes subtils             |
| **Dropout**         | 0.2 (20%)        | Force le modÃ¨le Ã  apprendre les patterns robustes, pas les titres spÃ©cifiques |
| **WeightedSampler** | Auto-Ã©quilibrage | Assure que chaque batch contient 50/50 Vrai/Faux                              |

### Seuil Dynamique (NouveautÃ© V3)

Au lieu d'utiliser le seuil classique de 0.50, le modÃ¨le calcule automatiquement le seuil optimal pour chaque dataset. Cela permet d'adapter la sensibilitÃ© du modÃ¨le selon la distribution des donnÃ©es.

**RÃ©sultats** :

- **PolitiFact** â†’ Seuil **0.45** (Ãªtre soupÃ§onneux pour ne rien rater)
- **GossipCop** â†’ Seuil **0.60** (Ãªtre strict pour filtrer le bruit)

---

## ğŸ“š RÃ©fÃ©rences

### Datasets

- [FakeNewsNet](https://github.com/KaiDMML/FakeNewsNet) â€” Shu et al., 2020

### ModÃ¨le

- [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692) â€” Liu et al., 2019

### Librairies

- [Hugging Face Transformers](https://huggingface.co/docs/transformers/)
- [Gradio Documentation](https://gradio.app/docs/)
- [PyTorch](https://pytorch.org/)

---

## ğŸ‘¤ Auteur

**scorpionTaj** â€” Master SDIA, UniversitÃ© Moulay Ismail
**ana3ss7z** â€” Master SDIA, UniversitÃ© Moulay Ismail
**Nawfal Khallou** â€” Master SDIA, UniversitÃ© Moulay Ismail

---

<p align="center">
  <i>DÃ©veloppÃ© avec â¤ï¸ pour le cours de NLP & Web Mining</i>
</p>
