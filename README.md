# D√©tection et Classification de Fake News avec LLM (RoBERTa)

[![Python 3.8+](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/downloads/)
[![Transformers](https://img.shields.io/badge/Transformers-4.x-green.svg)](https://huggingface.co/transformers/)
[![Gradio](https://img.shields.io/badge/Gradio-UI-orange.svg)](https://gradio.app/)

Ce projet propose un pipeline complet de Deep Learning pour d√©tecter les fake news en utilisant le mod√®le **RoBERTa** (Robustly Optimized BERT Approach). Il inclut un notebook d'entra√Ænement d√©taill√© et une application web interactive bas√©e sur **Gradio** pour tester le mod√®le en temps r√©el.

## üìÅ Structure du Projet

```
‚îú‚îÄ‚îÄ fake-news-detection-and-classification-using-llm.ipynb  # Notebook d'entra√Ænement principal
‚îú‚îÄ‚îÄ app.py                                                   # Application Gradio pour l'inf√©rence
‚îú‚îÄ‚îÄ requirements.txt                                         # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                                               # Ce fichier
‚îî‚îÄ‚îÄ mon_modele_fake_news/                                  # Dossier du mod√®le entra√Æn√©
    ‚îú‚îÄ‚îÄ config.json                                         # Configuration du mod√®le
    ‚îú‚îÄ‚îÄ model.safetensors                                   # Poids du mod√®le
    ‚îú‚îÄ‚îÄ vocab.json                                          # Vocabulaire
    ‚îú‚îÄ‚îÄ merges.txt                                          # Fichiers de fusion BPE
    ‚îú‚îÄ‚îÄ tokenizer_config.json                               # Config du tokenizer
    ‚îî‚îÄ‚îÄ special_tokens_map.json                             # Map des tokens sp√©ciaux
```

## üéØ Fonctionnalit√©s Cl√©s

| Composant | D√©tails |
|Chart | Description |
| **Donn√©es** | Utilisation des datasets **GossipCop** & **Politifact** (FakeNewsNet). |
| **Mod√®le** | Fine-tuning de `roberta-base` pour la classification binaire. |
| **Entra√Ænement** | Optimiseur AdamW, Warmup, Sampling pond√©r√© (Weighted Sampler) pour le d√©s√©quilibre des classes. |
| **Interface** | Application web **Gradio** pour tester des phrases personnalis√©es. |
| **P√©dagogie** | Le notebook inclut des d√©mos explicatives sur la tokenisation et l'analyse d'erreurs. |

## ‚öôÔ∏è Pr√©requis

- **Python:** 3.8 ou sup√©rieur
- **GPU:** Recommand√© pour l'entra√Ænement (Google Colab ou GPU local), Optionnel pour l'inf√©rence.

### Installation

1. Cloner le projet :

   ```bash
   cd "Votre/Chemin/Vers/Le/Projet"
   ```

2. Installer les d√©pendances :
   ```bash
   pip install -r requirements.txt
   ```
   _(Assurez-vous d'avoir `gradio`, `torch`, `transformers`, `scikit-learn` install√©s)_

## üöÄ Utilisation

### 1. Entra√Ænement du Mod√®le (Notebook)

Ouvrez et ex√©cutez le notebook `fake-news-detection-and-classification-using-llm.ipynb` pour :

- T√©l√©charger et pr√©parer les donn√©es.
- Entra√Æner le mod√®le RoBERTa.
- √âvaluer les performances (F1-score, Matrice de confusion).
- Sauvegarder le mod√®le dans le dossier `mon_modele_fake_news`.

### 2. Lancer l'Application Web (Demo)

Une fois le mod√®le entra√Æn√© (ou si vous avez d√©j√† le dossier `mon_modele_fake_news`), lancez l'interface :

```bash
python app.py
```

Ouvrez ensuite le lien local affich√© (g√©n√©ralement `http://127.0.0.1:7860`) dans votre navigateur.

## üìä Performances Attendues

Le mod√®le est √©valu√© principalement sur le dataset **GossipCop**.

- **Label 0 :** Vrai (Real)
- **Label 1 :** Faux (Fake)

L'application affiche la probabilit√© de confiance pour chaque classe.

## üõ†Ô∏è Configuration du Mod√®le

Le mod√®le utilis√© est `roberta-base` fine-tun√© avec les hyperparam√®tres suivants (configurables dans le notebook) :

- **Max Len:** 128 tokens
- **Batch Size:** 64
- **Learning Rate:** 2e-5
- **Epochs:** 5

## üìö R√©f√©rences

- [FakeNewsNet Dataset](https://github.com/KaiDMML/FakeNewsNet)
- [RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers/index)
